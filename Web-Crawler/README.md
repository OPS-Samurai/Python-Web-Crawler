# Jarvis Web Crawler v4.0 (Autonomic & Stealth)

Ein modularer, hochgradig flexibler Web-Crawler, entwickelt f√ºr die effiziente Extraktion von Daten aus Blogs und News-Portalen. Das System verf√ºgt √ºber eine automatische Strukturanalyse und ein interaktives Dashboard.

## üöÄ Features

* **Auto-Discovery**: Analysiert die Zielseite vorab und schl√§gt passende CSS-Selektoren vor.
* **Stealth-Modus**: Integrierte Cool-Down-Phasen (Throttling) nach 100 Seiten zur Vermeidung von IP-Sperren.
* **Pr√§zisions-Filter**: Kombination aus hartem Keyword-Filter und optionaler Blacklist.
* **Blackbox-Logging**: Detaillierte Fehlerprotokolle (`crawler_errors.log`) und HTML-Dumps bei Fehlern zur forensischen Analyse.
* **HTML Dashboard**: Automatisierte Erstellung eines interaktiven Dark-Mode Berichts mit Thumbnails und Direktlinks zum Angebot.

## üõ† Installation

### 1. **Repository klonen:**
   ```bash
   git clone [https://github.com/IHR_BENUTZERNAME/CrawlerPython.git](https://github.com/IHR_BENUTZERNAME/CrawlerPython.git)
   cd CrawlerPython
   ```
### Virtuelle Umgebung erstellen:

```bash
python -m venv .venv
.\.venv\Scripts\Activate
```

Abh√§ngigkeiten installieren:

```bash
pip install -r requirements.txt
```

## üìñ Nutzung
Starten Sie das Hauptskript:

```bash
python crawler.py
```
Das System f√ºhrt Sie durch den Prozess:

URL eingeben: Zieladresse (z.B. mein-deal.com).

Filter setzen: Keywords f√ºr die Suche festlegen.

Blacklisted Keywords: Keywords f√ºr die Blacklist festlegen. 

Recon akzeptieren: Die vorgeschlagenen Selektoren best√§tigen.

Dashboard sichten: Nach 10 Treffern √∂ffnet sich automatisch der HTML-Report.

## üìÅ Projektstruktur
crawler.py: Hauptsteuerung, Filterlogik und Dashboard-Generator.

ArticleFetcher.py: Die Crawling-Engine inkl. Stealth-Mechanismen.

CrawledArticle.py: Datenklasse f√ºr die Artikelstruktur.

requirements.txt: Ben√∂tigte Python-Bibliotheken (requests, beautifulsoup4).
